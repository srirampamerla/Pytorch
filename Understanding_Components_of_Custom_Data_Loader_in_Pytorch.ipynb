{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Components of Custom Data Loader in Pytorch"
      ],
      "metadata": {
        "id": "WJvM-NAacrto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rag_67_ZcbWq",
        "outputId": "f58d10fd-fc1b-4a0c-ba5f-02f1ffe79f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path=kagglehub.dataset_download(\"mirichoi0218/insurance\")\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRGFqn9Lc0lH",
        "outputId": "b9cc6541-5d54-4d9c-d5ed-2cb65c7a13e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mirichoi0218/insurance?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16.0k/16.0k [00:00<00:00, 18.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "/root/.cache/kagglehub/datasets/mirichoi0218/insurance/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/root/.cache/kagglehub/datasets/mirichoi0218/insurance/versions/1\")"
      ],
      "metadata": {
        "id": "W5zWrEk-dBlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa47c1f-af3a-4735-fa35-2d686d9b83f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['insurance.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(os.path.join(path,\"insurance.csv\"))"
      ],
      "metadata": {
        "id": "y0OoVxDxgcKn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3W4iYzWPgvDP",
        "outputId": "313b522b-1544-482b-c40c-c0debfc63938"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8598da4f-7c60-43dd-8f3f-489ae142f6ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8598da4f-7c60-43dd-8f3f-489ae142f6ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8598da4f-7c60-43dd-8f3f-489ae142f6ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8598da4f-7c60-43dd-8f3f-489ae142f6ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a0de400-1800-4c5a-bfc5-3cb4ee7195d4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a0de400-1800-4c5a-bfc5-3cb4ee7195d4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a0de400-1800-4c5a-bfc5-3cb4ee7195d4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1338,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          21,\n          45,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.098186911679017,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          23.18,\n          26.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"southeast\",\n          \"northeast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12110.011236693994,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          8688.85885,\n          5708.867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N09ekrF1g1jx",
        "outputId": "d907d5f1-5a0e-4aec-fbe9-08efcbabee8c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1338 entries, 0 to 1337\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1338 non-null   int64  \n",
            " 1   sex       1338 non-null   object \n",
            " 2   bmi       1338 non-null   float64\n",
            " 3   children  1338 non-null   int64  \n",
            " 4   smoker    1338 non-null   object \n",
            " 5   region    1338 non-null   object \n",
            " 6   charges   1338 non-null   float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 73.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "X_train_tensor has 1000000 rows  -> To run this we need let's think we need to use 10 gb of memory --> If not suffivient we can say out of memory\n",
        "\n",
        "if u have that amount of memory but still we had the issue to update the weights and bias using backpropgation it needs to iterate all over the rows it will be impossible\n",
        "\n",
        "\n",
        "we are teaching human :A book of 1000 pages --> student has issue in 10 th page , then student i am not able to understand.\n",
        "\n",
        "1000 pages\n",
        "100 epoch\n",
        "we need 10 pages feedback\n",
        "\n",
        "1000/10=100 iterations\n",
        "\n",
        "each epoch has 100 iterations . 100 epochs *100 iterations\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "2eNR5GR-jH6w",
        "outputId": "13a42254-2fe5-43af-83de-52de70ee312c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nX_train_tensor has 1000000 rows  -> To run this we need let's think we need to use 10 gb of memory --> If not suffivient we can say out of memory\\n\\nif u have that amount of memory but still we had the issue to update the weights and bias using backpropgation it needs to iterate all over the rows it will be impossible\\n\\n\\nwe are teaching human :A book of 1000 pages --> student has issue in 10 th page , then student i am not able to understand.\\n\\n1000 pages\\n100 epoch\\nwe need 10 pages feedback\\n\\n1000/10=100 iterations\\n\\neach epoch has 100 iterations . 100 epochs *100 iterations\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KvBKg8tammz-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset\n",
        "\n",
        "train_df,test_df=train_test_split(df,test_size=0.2,random_state=42)\n"
      ],
      "metadata": {
        "id": "ihRDQhIlmdkC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders={}\n",
        "for col in df.select_dtypes(include=['object']):\n",
        "  le=LabelEncoder()\n",
        "  train_df[col]=le.fit_transform(train_df[col])\n",
        "  test_df[col]=le.transform(test_df[col])\n",
        "  label_encoders[col]=le"
      ],
      "metadata": {
        "id": "ADVRVl7dm0pM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X_train = train_df.drop('charges', axis=1).values\n",
        "y_train = train_df['charges'].values\n",
        "X_test = test_df.drop('charges', axis=1).values\n",
        "y_test = test_df['charges'].values"
      ],
      "metadata": {
        "id": "MC5-h9YHnSY5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_yAIPw0kwWj0",
        "outputId": "ab5d35e2-18cf-45aa-ed94-6e859187962e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age  sex     bmi  children  smoker  region\n",
              "560    46    0  19.950         2       0       1\n",
              "1285   47    0  24.320         0       0       0\n",
              "1142   52    0  24.860         0       0       2\n",
              "969    39    0  34.320         5       0       2\n",
              "486    54    0  21.470         3       0       1\n",
              "...   ...  ...     ...       ...     ...     ...\n",
              "1095   18    0  31.350         4       0       0\n",
              "1130   39    0  23.870         5       0       2\n",
              "1294   58    1  25.175         0       0       0\n",
              "860    37    0  47.600         2       1       3\n",
              "1126   55    1  29.900         0       0       3\n",
              "\n",
              "[1070 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d84685ed-0e3f-46c2-b262-15239752b9a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>19.950</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1285</th>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>24.320</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>24.860</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>34.320</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>21.470</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>31.350</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>23.870</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>25.175</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>47.600</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>29.900</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1070 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d84685ed-0e3f-46c2-b262-15239752b9a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d84685ed-0e3f-46c2-b262-15239752b9a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d84685ed-0e3f-46c2-b262-15239752b9a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dfc19e45-babf-4b8c-958d-031efeab484f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfc19e45-babf-4b8c-958d-031efeab484f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dfc19e45-babf-4b8c-958d-031efeab484f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f543fb0b-8c9d-4dd8-bb33-9b3db6b1e1f3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f543fb0b-8c9d-4dd8-bb33-9b3db6b1e1f3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train",
              "summary": "{\n  \"name\": \"X_train\",\n  \"rows\": 1070,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          35,\n          33,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.043385672727494,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 494,\n        \"samples\": [\n          27.3,\n          31.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the features\n",
        "scaler=StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Zp7MaC1ZnXrs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HS1FHvmE3F5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Os0asKyKwFQW",
        "outputId": "95336e31-6713-4872-97a8-1223ab7ab33d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'values'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1240430652.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert into Tensor\n",
        "\n",
        "X_train_tensor=torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train_tensor=torch.tensor(y_train,dtype=torch.float32).view(-1,1) # y_train the data will be in pandas. y_train.values only we are getting values\n",
        "X_test_tensor=torch.tensor(X_test,dtype=torch.float32)\n",
        "y_test_tensor=torch.tensor(y_test,dtype=torch.float32).view(-1,1)\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "VIsNKoll3GQc"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define NN\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNNRegresionModel(nn.Module):\n",
        "  def __init__(self,input_dim):\n",
        "    super(SimpleNNRegresionModel,self).__init__()\n",
        "    self.network= nn.Sequential(\n",
        "        nn.Linear(input_dim,64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128,1)\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    return self.network(X)"
      ],
      "metadata": {
        "id": "Wf1Gl-ed3lzS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "input_dim=X_train_tensor.shape[1]\n",
        "\n",
        "model=SimpleNNRegresionModel(input_dim)"
      ],
      "metadata": {
        "id": "jIghY1oG3tz2"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimization\n",
        "\n",
        "criterion=nn.MSELoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "HRYdVhkB3xYc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs=1000\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output=model(X_train_tensor)\n",
        "  loss=criterion(output,y_train_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch+1)%1000==0:\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4kkW_5435wN",
        "outputId": "62a122a6-a052-4ca5-93d5-2e6b99a766aa"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1000/1000], Loss: 22733206.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Dataset torch.utils.data.Dataset # we can create the new dataset. we will tell our pytorch that how we want to retrieve the dataset, how we want to process the dataset\n",
        "2. DataLoader torch.utils.data.DataLoader # It will helps to wrap the dataset into an iterable object that lpads the data in bunches.\n",
        "\n",
        "If i want 1000 rows in a single iteration, data loader will wrap the dataset and ask data dataset to provide 1000 ros in single ieration."
      ],
      "metadata": {
        "id": "QBy_IF5NkHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating our custom dataset in pytorch\n",
        "\n",
        "#init() - Initialized the datset, loads data, applied preprocessing\n",
        "# len() - return the total numbers of samples in the datsaet\n",
        "# getitem()  - it defines how to reterive the single data sample when index is provided"
      ],
      "metadata": {
        "id": "Zd8djWf7ndj3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "YIWFPLSOpGzq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InsuranceDataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X=X\n",
        "    self.y=y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    features=torch.tensor(self.X[index],dtype=torch.float32)\n",
        "    target=torch.tensor(self.y[index],dtype=torch.float32)\n",
        "    return features,target\n",
        "\n"
      ],
      "metadata": {
        "id": "FBn8D8RWpNLe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHjhI1Iwwx7C",
        "outputId": "e6bccefd-78ae-4719-f5af-bc2a31d36ebf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1070, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1070/32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ47KUHcw0Qf",
        "outputId": "0e170fc5-0822-42fe-c168-83d1ffd58fbd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.4375"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__init__ is the constructor of the class.\n",
        "\n",
        "It runs automatically when you create an object:\n",
        "\n",
        "Because X is stored as self.X, which belongs to the object, not just to __init__"
      ],
      "metadata": {
        "id": "vMVuzMq0r06A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= InsuranceDataset(X_train,y_train)"
      ],
      "metadata": {
        "id": "FbwxxAmIr1Nw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=DataLoader(dataset,batch_size=32,shuffle=True) # shuffle means random shuffle and num_workers\n",
        "# print(dataloader)"
      ],
      "metadata": {
        "id": "iN9Bm7UjudgE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataloader:\n",
        "    print(batch)\n",
        "    break\n",
        "\n",
        "    # batch = (inputs, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn4cd2Ldxu3g",
        "outputId": "20ef80f0-4aec-47b4-86f7-49e122cd0b98"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[36.0000,  1.0000, 31.5000,  0.0000,  0.0000,  3.0000],\n",
            "        [47.0000,  1.0000, 29.8000,  3.0000,  1.0000,  3.0000],\n",
            "        [55.0000,  1.0000, 37.3000,  0.0000,  0.0000,  3.0000],\n",
            "        [43.0000,  0.0000, 32.5600,  3.0000,  1.0000,  2.0000],\n",
            "        [18.0000,  0.0000, 21.6600,  0.0000,  1.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 35.8150,  0.0000,  0.0000,  1.0000],\n",
            "        [51.0000,  0.0000, 37.7300,  1.0000,  0.0000,  2.0000],\n",
            "        [48.0000,  0.0000, 33.1100,  0.0000,  1.0000,  2.0000],\n",
            "        [33.0000,  1.0000, 22.7050,  0.0000,  0.0000,  1.0000],\n",
            "        [24.0000,  1.0000, 40.1500,  0.0000,  1.0000,  2.0000],\n",
            "        [51.0000,  1.0000, 39.7000,  1.0000,  0.0000,  3.0000],\n",
            "        [18.0000,  0.0000, 36.8500,  0.0000,  1.0000,  2.0000],\n",
            "        [21.0000,  1.0000, 31.1000,  0.0000,  0.0000,  3.0000],\n",
            "        [31.0000,  1.0000, 31.0650,  3.0000,  0.0000,  1.0000],\n",
            "        [28.0000,  0.0000, 37.6200,  1.0000,  0.0000,  2.0000],\n",
            "        [51.0000,  0.0000, 36.6700,  2.0000,  0.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 34.7000,  2.0000,  1.0000,  3.0000],\n",
            "        [31.0000,  0.0000, 23.6000,  2.0000,  0.0000,  3.0000],\n",
            "        [31.0000,  0.0000, 36.6300,  2.0000,  0.0000,  2.0000],\n",
            "        [21.0000,  0.0000, 21.8900,  2.0000,  0.0000,  2.0000],\n",
            "        [33.0000,  0.0000, 32.9000,  2.0000,  0.0000,  3.0000],\n",
            "        [19.0000,  1.0000, 20.3000,  0.0000,  0.0000,  3.0000],\n",
            "        [49.0000,  0.0000, 33.3450,  2.0000,  0.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 25.2000,  0.0000,  0.0000,  3.0000],\n",
            "        [55.0000,  1.0000, 35.2450,  1.0000,  0.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 39.2700,  2.0000,  0.0000,  2.0000],\n",
            "        [30.0000,  0.0000, 39.0500,  3.0000,  1.0000,  2.0000],\n",
            "        [19.0000,  0.0000, 32.9000,  0.0000,  0.0000,  3.0000],\n",
            "        [24.0000,  0.0000, 30.2100,  3.0000,  0.0000,  1.0000],\n",
            "        [61.0000,  0.0000, 28.2000,  0.0000,  0.0000,  3.0000],\n",
            "        [47.0000,  1.0000, 36.0800,  1.0000,  1.0000,  2.0000],\n",
            "        [27.0000,  0.0000, 20.0450,  3.0000,  1.0000,  1.0000]]), tensor([ 4402.2329, 25309.4883, 20630.2832, 40941.2852, 14283.4590,  4320.4106,\n",
            "         9877.6074, 40974.1641, 21984.4707, 38126.2461,  9391.3457, 36149.4844,\n",
            "         1526.3120,  5425.0234,  3766.8838, 10848.1348, 36397.5742,  4931.6470,\n",
            "         4949.7588,  3180.5100,  5375.0381,  1242.2600, 10370.9121, 11837.1602,\n",
            "        11394.0654,  3500.6123, 40932.4297,  1748.7740,  4618.0801, 13041.9209,\n",
            "        42211.1367, 16420.4941])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx,(features,targets) in enumerate(dataloader): # it will create 33 batches\n",
        "  print(f\"Batch Index: {batch_idx+1}\")\n",
        "  print(f\"Features Shape: {features.shape}\")\n",
        "  print(f\"Targets: {targets.shape}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKOpxE7NvKmp",
        "outputId": "a788254e-f13a-45c8-ec86-9432f61d454f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Index: 1\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 2\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 3\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 4\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 5\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 6\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 7\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 8\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 9\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 10\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 11\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 12\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 13\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 14\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 15\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 16\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 17\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 18\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 19\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 20\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 21\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 22\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 23\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 24\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 25\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 26\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 27\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 28\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 29\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 30\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 31\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 32\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 33\n",
            "Features Shape: torch.Size([32, 6])\n",
            "Targets: torch.Size([32])\n",
            "Batch Index: 34\n",
            "Features Shape: torch.Size([14, 6])\n",
            "Targets: torch.Size([14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1070/32\n",
        "# it will created 33 batches with"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHE0WRoDvpLI",
        "outputId": "28d3cf25-362a-4b3c-a12b-1dda5e33668c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.4375"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx,(batch_x,batch_y) in enumerate(dataloader):\n",
        "    print(f\"Current Batch :{batch_idx}\")\n",
        "    optimizer.zero_grad()\n",
        "    predictions=model(batch_x)\n",
        "    loss=criterion(predictions,batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Batch[{batch_idx+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if (epoch+1)%100==0:\n",
        "      print(\"**\"*60)\n",
        "      print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "      print(\"**\"*60)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "faO3XUk5yJCj",
        "outputId": "1bbfccba-2c20-479d-e349-00e0806b679f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch[34/1000], Loss: 100314208.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 197072144.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 111864072.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 165766288.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 150586800.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 195075552.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 132139064.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 92802856.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 227632464.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 170903888.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 118976072.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 149275072.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 136106080.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 109839824.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 133335616.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 123090328.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 134814032.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 76128176.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 49470440.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 163483216.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 69671248.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 98420256.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 139004000.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 266736208.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 208718048.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 121369752.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 193729568.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 113483088.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 98831488.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 148675648.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 121352880.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 105849744.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 236400528.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 190548384.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 174596800.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 162771360.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 178089696.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 181323888.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 130386176.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 151447968.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 99747136.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 125565488.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 112112856.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 59885772.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 146871600.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 127369000.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 153449904.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 135477584.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 75911664.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 173162304.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 83326080.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 143331088.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 92657288.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 100891328.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 181255168.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 116591680.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 203885472.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 121483800.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 161141984.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 117474224.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 115108272.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 342567936.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 123638168.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 172753808.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 163592864.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 212782592.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 184659104.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 187713888.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 65964184.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 107247968.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 146228016.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 93600832.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 112956624.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 80856136.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 250705088.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 129464488.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 175928144.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 186663328.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 99412960.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 116918912.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 125732936.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 104541216.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 180824736.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 169354992.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 153456432.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 148524496.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 147425056.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 160776864.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 141207872.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 153105984.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 138736464.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 202080528.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 145574736.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 142874720.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 170820224.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 107056152.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 193429008.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 140794752.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 63614044.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 169255952.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 165736176.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 156576512.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 122904768.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 111327288.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 129541136.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 97966288.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 194428496.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 158909584.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 133201224.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 139192400.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 89323072.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 104942264.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 179594080.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 95848160.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 68600872.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 202098496.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 103418728.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 206430320.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 201432272.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 222770448.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 53917776.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 127202768.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 175092544.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 69656536.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 120057952.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 240416224.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 134926896.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 99203208.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 122362760.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 153556208.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 272046240.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 145582032.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 137764128.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 203543472.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 181781664.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 118558096.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 84817504.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 99372616.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 99745864.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 119930024.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 133695728.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 111813072.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 132503832.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 73758952.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 218814592.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 156745120.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 152526352.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 132080104.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 146655952.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 165421680.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 200428000.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 142783952.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 243844064.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 159214864.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 226588528.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 67302760.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 176817840.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 141507296.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 186172560.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 142816592.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 205486592.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 84721096.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 129224144.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 136318512.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 197933728.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 187741344.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 152363632.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 130265248.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 113337000.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 54119564.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 95711272.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 199540128.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 173434352.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 132070976.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 142402864.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 130321504.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 73262232.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 63929436.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 127324176.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 120901320.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 230885184.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 150619664.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 137910448.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 140260448.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 184603520.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 72432840.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 242736048.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 91893624.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 248400272.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 140934560.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 109003664.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 86418480.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 183792384.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 91221552.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 154913568.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 226097200.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 94509680.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 137515520.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 165659248.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 170847552.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 125547264.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 87587832.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 177454864.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 165566240.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 158925216.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 171965840.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 93320720.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 256297488.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 88592032.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 166760736.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 201621456.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 139671616.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 122260880.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 207412416.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 131574600.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 137439344.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 204237664.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 133207440.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 150298736.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 82827352.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 210172736.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 120376064.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 138718336.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 75692688.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 213999920.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 175984720.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 141583568.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 107932744.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 130757104.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 88469960.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 127393096.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 248982192.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 174613632.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 94921448.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 120941160.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 103888264.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 146651552.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 67822016.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 124870240.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 205555824.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 197355168.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 170457152.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 167458704.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 196427520.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 133143520.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 93042048.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 177029664.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 170183680.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 205348112.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 79540944.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 102861272.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 239649360.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 171053248.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 187084448.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 156122064.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 114541616.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 92949920.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 128797576.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 181652048.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 141141504.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 214536064.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 75865704.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 117215784.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 67270208.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 166346480.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 112363176.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 52872168.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 183474848.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 113194344.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 114216216.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 128444184.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 109127640.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 188812144.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 100983896.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 102933152.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 90810488.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 161564512.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 169504656.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 185086688.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 107452224.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 63210716.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 126969064.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 133851088.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 134578336.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 196605456.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 98506992.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 111826968.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 123337296.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 85007552.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 138249760.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 196329344.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 137614432.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 164926112.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 183289360.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 143690656.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 115856248.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 138565408.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 244724928.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 169067600.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 165851632.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 214475760.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 158393520.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 121257312.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 277788032.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 81349032.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 116839896.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 163132336.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 162195152.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 186402352.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 123710896.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 80765184.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 94827904.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 156544752.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 121243744.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 105052416.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 163377632.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 130383808.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 90651808.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 250865680.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 166237856.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 148301616.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 109554328.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 174599696.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 119380576.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 158891776.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 99081704.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 198075552.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 99256680.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 165155008.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 186287648.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 181430416.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 53690460.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 220635168.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 178617056.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 91053064.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 189486672.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 152063376.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 114725936.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 96367920.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 241960096.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 103583208.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 130901624.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 105820048.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 181077840.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 140935024.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 154104112.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 206944080.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 182229072.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 178866720.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 190069152.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 117669352.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 162237120.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 95605928.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 59646068.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 128160632.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 183811456.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 165831968.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 76273128.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 139128160.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 148144432.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 141588912.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 157693216.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 93706968.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 104607392.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 186886912.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 288128000.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 168440992.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 50146744.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 107034984.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 185521568.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 73394160.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 168682192.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 65772032.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 230558704.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 148923152.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 115069680.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 125822760.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 210870928.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 172759776.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 173958688.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 55089440.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 170674880.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 69825816.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 169510416.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 178362144.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 160298224.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 95604208.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 220386496.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 88763872.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 100236336.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 55005744.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 166749168.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 132929688.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 176702080.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 139298864.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 229914464.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 257637296.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 236357296.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 108118328.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 174591648.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 108581640.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 159418528.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 111727936.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 138559664.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 168963024.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 132786816.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 166585152.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 61990136.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 65137372.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 183460224.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 151046240.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 74946280.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 104301184.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 106410208.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 118425696.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 130923096.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 190892352.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 240857792.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 136086320.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 95562536.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 243539440.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 234829584.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 155265344.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 198599728.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 81283312.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 69958912.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 126370760.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 84628824.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 103584920.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 96164200.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 93138936.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 136336288.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 152679584.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 38482600.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 162564224.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 131813392.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 220690976.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 150843120.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 190821792.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 313632224.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 140888336.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 139363328.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 116890376.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 128606656.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 101230584.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 187429408.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 83320280.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 164802864.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 119578984.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 120397824.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 288965216.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 170130688.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 127874256.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 92221008.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 118032480.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 116639240.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 186921184.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 124979416.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 179163792.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 132731920.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 76116216.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 194586112.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 250342352.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 109641512.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 163928816.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 86908840.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 245280960.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 146533248.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 165965888.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 159498128.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 105936424.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 134263648.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 183273072.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 195072624.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 69822888.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 85152320.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 89330920.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 91582184.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 250178096.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 90785776.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 178053616.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 183922656.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 175566656.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 126190168.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 95383968.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 196177280.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 150206544.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 99729208.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 168405856.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 138468096.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 74683584.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 181311184.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 190379120.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 212677264.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 188518320.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 55746052.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 175382480.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 114906512.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 123166816.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 104916904.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 149522304.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 106913168.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 75235712.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 266972368.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 110174552.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 74089848.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 132173376.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 236154048.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 166140416.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 125716904.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 55561948.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 202103584.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 92241032.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 114990544.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 139608544.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 142715824.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 146449600.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 242562624.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 184828976.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 110146960.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 165244144.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 201694432.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 194102976.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 237558784.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 93315168.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 167417216.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 148926768.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 97561536.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 140586080.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 112227408.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 125578392.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 154781408.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 80629608.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 141302816.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 139756256.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 113137168.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 77608408.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 264548832.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 133077056.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 114383872.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 41577536.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 111841848.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 143116112.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 179281440.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 258646480.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 113388536.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 242350480.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 113266904.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 313920864.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 100085504.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 106772120.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 118766824.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 178164528.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 171251168.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 163355808.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 262393152.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 95053072.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 146255456.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 111466144.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 130859616.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 161504960.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 115215512.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 146955632.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 206368096.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 141155888.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 66099752.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 153260160.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 115372544.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 118443168.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 128708712.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 122432928.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 112194736.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 133383976.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 120423584.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 156891360.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 84483392.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 201873536.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 112091256.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 184125440.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 188314272.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 168218096.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 144254160.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 178459152.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 133610320.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 101866256.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 138514176.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 119187584.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 79311640.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 142353472.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 108687168.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 143266848.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 188921872.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 134762048.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 99166064.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 105190528.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 161542240.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 133815872.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 185424832.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 150424512.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 128803504.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 147624096.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 95185304.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 148421344.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 177935744.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 176822880.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 125464552.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 131710840.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 133826240.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 200742048.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 208837856.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 180707552.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 95916992.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 214868656.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 122886112.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 78846552.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 140294144.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 140102144.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 163618704.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 195543616.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 253692816.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 65486316.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 79323776.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 150440944.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 104745576.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 269650208.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 132644384.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 180039488.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 101101496.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 163234944.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 148376608.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 162020224.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 111904992.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 149015440.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 114026000.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 161877632.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 111988040.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 63384904.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 152884992.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 188401568.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 100296848.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 244149248.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 79857896.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 218227360.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 90027600.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 161421712.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 200472448.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 104390848.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 179125680.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 138115424.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 152357136.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 156993024.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 147447184.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 209490256.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 114504432.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 91471792.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 148900944.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 116577992.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 85914640.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 131216896.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 149084720.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 107983440.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 126592128.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 100628888.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 202962976.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 188232432.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 207145184.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 100771696.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 149547568.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 136185216.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 131125336.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 128072768.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 185640480.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 191241456.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 169272080.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 189632064.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 180996240.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 109920784.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 137949216.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 86910672.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 159874544.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 104344240.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 97301592.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 151353424.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 82299376.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 146374704.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 151020752.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 115940640.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 68344448.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 195534400.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 107926136.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 64180088.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 222907840.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 70399656.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 107927696.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 96911312.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 135494960.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 169391504.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 166466160.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 188379584.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 167967104.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 310868064.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 122457208.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 166402304.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 216143984.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 175839136.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 175405440.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 93121248.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 155214912.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 117505256.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 189179728.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 188585344.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 103014104.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 106143376.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 212440000.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 61243100.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 176686720.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 72521800.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 120014488.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 112209000.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 142627264.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 229150208.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 111111088.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 62437504.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 101843328.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 157292128.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 178905760.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 76770256.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 113675280.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 256025360.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 96764128.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 214749360.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 143150064.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 80361280.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 146436384.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 146479264.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 99160016.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 122878280.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 225088320.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 122681432.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 117506888.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 114695560.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 167130880.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 107152312.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 232807152.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 175305728.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 265647312.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 172426448.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 135400608.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 125860176.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 160670016.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 60335756.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 149543616.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 148407744.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 134275136.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 155897152.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 97900960.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 212913280.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 96205712.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 154234944.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 85065472.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 111944496.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 105677560.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 90723120.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 257922192.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 218448848.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 144027536.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 100020240.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 238778496.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 120211536.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 145856816.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 72523416.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 102098160.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 260846064.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 254853040.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 175547264.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 123267504.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 172908992.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 135737280.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 114604504.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 120521360.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 148295680.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 168216256.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 67267592.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 80816688.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 147743024.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 138674832.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 113921856.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 133317136.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 149786400.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 130023264.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 120064288.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 109085920.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 146101600.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 186248592.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 174645696.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 135132288.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 119205544.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 138724368.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 125232912.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 259794096.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 93247424.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 217824256.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 69576896.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 124386704.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 91009952.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 166660560.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 205686192.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 84381224.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 112236928.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 148595776.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 159197664.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 219200496.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 128837312.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 184322912.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 162276256.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 196107792.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 186855808.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 118349224.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 117744352.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 170198176.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 74766992.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 191464256.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 172747552.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 146692592.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 138702752.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 112427960.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 83891808.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 78779128.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 182526192.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 213644944.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 116476384.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 114543312.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 286925280.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 169293664.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 137320816.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 49104708.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 157635504.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 151856032.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 112925680.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 154316592.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 145005232.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 148204192.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 129774280.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 165335904.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 134940368.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 95065544.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 190087520.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 146454768.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 174051696.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 150761648.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 238517984.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 172984688.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 85765024.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 94259632.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 154345264.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 255985888.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 189556800.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 132566856.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 156042784.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 172385888.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 112606072.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 94689728.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 81676392.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 136277072.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 72660480.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 185174784.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 188952816.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 141475696.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 109935736.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 176608992.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 127715608.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 140549104.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 158963440.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 89731064.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 187422080.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 167095760.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 85843976.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 116239072.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 187370928.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 131434944.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 195155872.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 180326560.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 208548800.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 67520352.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 176769136.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 221826688.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 88504296.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 130603536.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 193328768.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 64487916.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 155986080.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 127674552.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 127772192.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 90228864.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 110765936.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 152641744.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 134519888.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 143114944.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 119065952.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 152422432.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 162142384.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 188466560.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 175093088.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 239466192.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 182018992.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 90003064.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 100189032.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 186210304.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 106510512.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 172856496.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 170776544.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 132067008.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 101778528.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 120406824.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 262160064.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 165428528.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 51100688.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 170016304.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 119984840.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 186477520.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 134333632.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 144934096.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 168829168.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 169372944.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 83551552.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 102080840.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 157074960.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 125527864.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 210567328.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 85298288.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 130758800.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 139819808.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 109865168.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 269848704.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 149866640.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 128498608.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 90015168.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 112997616.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 202076640.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 173482304.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 232626688.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 201559744.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 80657064.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 106308968.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 133130672.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 158686848.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 127405032.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 192827984.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 108767352.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 87391752.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 81790160.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 164039568.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 195771888.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 91461848.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 94340496.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 127938064.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 81714696.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 133727608.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 166403376.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 121250744.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 102493784.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 177665856.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 168460064.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 263152480.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 207871088.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 147463760.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 64854016.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 165683616.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 121654392.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 134797152.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 89521904.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 121977520.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 188036896.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 143407328.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 136495824.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 173669824.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 153856976.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 114963024.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 144269632.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 153939552.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 190263568.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 138738304.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 162644448.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 155082976.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 160719872.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 162373328.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 185296848.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 134919824.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 143024992.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 84063496.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 105703368.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 151122800.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 119554512.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 194921136.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 92753968.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 108562400.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 74697104.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 113440088.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 226015952.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 281474752.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 102677696.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 96398424.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 170110112.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 203922448.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 149092880.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 180706048.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 153112496.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 150479472.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 233760848.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 158600912.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 63179984.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 153387600.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 187847968.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 115344872.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 112211728.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 155627104.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 137719840.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 165169232.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 182128256.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 46671672.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 216197504.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 191069824.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 191159856.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 94123984.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 89964776.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 256489104.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 100210496.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 226324160.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 200086848.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 82401024.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 133161592.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 182730896.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 120524048.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 247051680.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 142711248.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 92266464.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 84070776.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 59359036.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 170584000.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 162962896.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 110421808.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 151749648.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 93918224.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 218083104.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 96699672.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 245315120.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 130219264.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 98519008.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 188090960.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 216744992.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 148668272.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 91341672.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 53136356.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 129499104.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 68817664.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 165446224.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 231677440.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 131514248.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 69910784.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 184381424.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 144761712.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 175696000.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 194884368.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 136793136.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 171130752.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 150413840.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 138528096.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 150887760.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 157309520.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 149673936.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 205442560.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 67378896.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 130056528.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 179682032.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 147327120.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 143408656.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 178677456.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 143217120.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 164608416.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 128239856.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 124409928.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 147101136.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 123133008.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 116413328.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 174943712.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 108339224.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 81106376.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 102977768.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 63022184.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 187133360.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 193184720.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 160789488.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 264886848.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 219529152.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 155899456.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 117398144.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 103206976.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 64956556.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 138223056.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 114959920.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 251120336.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 78354144.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 223699984.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 115229856.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 155766208.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 99638776.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 91180952.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 90874200.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 122909608.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 153724864.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 131570520.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 64193252.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 110937728.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 134200472.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 144243792.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 171634560.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 129787768.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 154145856.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 192950736.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 146559280.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 167327232.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 97169400.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 205649504.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 57683884.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 107314288.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 142598416.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 97852224.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 81857936.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 193519920.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 94151984.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 105700496.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 200298144.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 143344480.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 131735472.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 258926304.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 168202448.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 169274960.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 166341008.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 87813976.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 107643128.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 212382880.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 104264376.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 227607392.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 90873376.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 230240752.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 138643744.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 134529824.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 147420656.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 153555792.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 116099736.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 202976832.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 92370952.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 163980992.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 167845376.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 108398840.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 146967648.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 186565360.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 57838220.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 84738896.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 65291184.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 79612632.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 129082336.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 83918608.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 120813760.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 179110224.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 86843720.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 296413184.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 287618880.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 119807216.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 89768832.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 133432288.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 189999488.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 103311424.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 205446496.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 144662640.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 136554288.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 192807312.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 87430800.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 257001568.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 131300040.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 131595840.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 58024584.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 177934720.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 147699488.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 119330192.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 203820192.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 148340080.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 163972592.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 169472832.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 162299648.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 215702192.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 112877624.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 125264640.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 175383824.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 147575888.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 143859648.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 128972800.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 105693192.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 306889600.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 120299936.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 111064704.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 94960808.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 101549616.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 126518376.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 82516368.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 129412712.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 111293632.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 144096976.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 128728624.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 82051208.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 186359488.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 186028608.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 189658912.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 137449824.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 109182352.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 135437632.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 168720880.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 72726048.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 204884736.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 128791520.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 315846464.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 170068000.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 217386720.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 107145776.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 121384696.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 147451088.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 205020352.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 158069920.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 95426784.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 251701600.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 101452216.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 138194336.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 138055168.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 128957640.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 135915424.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 115081768.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 186518016.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 158464528.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 66536960.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 252292656.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 113960216.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 230328992.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 82568824.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 126239248.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 190184720.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 200834064.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 179119280.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 84942408.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 177866896.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 133593272.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 154978032.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 88971376.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 113813072.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 152074720.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 149415600.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 106107416.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 87729656.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 142378896.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 101635664.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 224682448.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 124297424.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 74671952.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 82806576.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 153042304.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 99847560.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 172848176.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 66095160.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 157440080.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 182089920.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 85780600.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 151930736.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 190967168.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 134414512.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 141011984.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 185912464.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 103902016.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 160195616.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 124874600.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 220198976.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 86650352.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 126983856.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 160483104.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 166464640.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 121454248.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 151379072.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 212488144.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 195306864.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 108319640.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 114514144.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 187114496.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 131024032.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 199412768.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 128036288.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 95439624.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 185500000.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 132238448.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 78314008.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 151732800.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 131237288.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 172467792.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 131065264.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 131377992.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 149986336.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 100371608.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 114159264.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 168522272.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 70462464.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 115198976.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 189694224.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 148471696.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 144238256.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 236427568.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 192168496.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 115849672.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 102391608.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 168530592.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 149410384.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 134690256.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 181859552.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 158010144.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 162920848.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 121881536.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 108558960.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 146959888.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 147725856.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 227383136.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 157338064.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 174719968.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 201642432.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 128303656.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 213242480.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 157711664.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 115264016.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 134853232.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 111727760.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 132390144.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 182476480.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 179972080.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 88568280.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 167900896.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 213056368.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 134123328.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 85548248.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 132150128.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 125719920.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 186153216.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 72000208.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 112841176.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 69490544.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 178572944.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 245387648.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 131687880.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 144219280.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 211142816.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 106667920.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 180920160.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 137875472.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 120637152.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 81837176.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 127928360.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 142471696.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 80967240.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 113050248.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 229849200.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 104396792.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 233281968.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 152660928.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 147930704.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 104418440.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 114573344.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 141778464.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 152384304.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 155592064.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 131471344.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 105654136.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 156175008.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 137789152.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 135024208.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 122161680.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 291028096.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 119400792.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 119488984.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 130552528.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 141375536.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 212972000.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 137635136.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 99614216.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 126492624.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 169417072.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 137070592.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 125406528.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 150133392.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 167145968.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 100225880.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 195840336.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 285460544.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 145782768.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 203516080.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 119649128.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 108130232.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 141180720.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 193641504.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 169931552.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 144995552.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 148155744.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 197512880.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 100178848.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 102053744.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 145170784.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 110078352.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 111463496.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 137200976.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 125920848.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 233929984.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 103071472.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 111693600.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 106831384.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 162393760.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 65949948.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 175100896.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 172007184.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 122244208.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 100821200.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 209969328.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 135555472.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 158247328.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 103124936.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 171407408.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 71646832.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 172856880.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 266940592.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 182020672.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 183652272.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 87206312.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 97944440.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 166875312.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 257488448.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 169558560.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 259314176.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 138906928.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 128214832.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 194080480.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 66070944.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 149924016.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 174460192.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 135272496.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 226076640.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 66609488.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 56347576.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 152072192.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 71646344.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 170277760.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 176021696.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 159323344.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 140274432.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 140900624.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 106802464.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 95553128.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 158958096.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 163950848.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 39388240.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 81731264.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 74019760.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 106175152.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 98664320.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 110277104.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 82236968.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 65212108.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 130418024.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 116505936.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 84691312.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 188073920.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 107029696.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 124026576.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 235824960.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 175357360.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 121773728.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 250733152.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 264657424.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 77075424.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 219037216.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 103559136.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 136552512.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 195446000.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 211625008.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 107030968.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 90774112.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 224554288.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 220173776.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 146090544.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 133452520.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 80472544.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 133800560.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 147970064.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 139542784.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 138900496.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 192309600.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 52708984.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 114305648.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 123415760.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 140053200.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 71778344.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 168093008.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 138551408.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 117136224.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 136670176.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 181609088.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 118482544.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 206788976.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 143350080.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 180239696.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 88062008.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 92977752.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 234271408.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 65507000.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 87506984.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 152938528.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 163943232.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 164410496.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 207356192.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 145173168.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 165931968.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 160831872.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 145309904.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 133135056.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 156951952.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 135379744.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 208902976.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 230412624.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 131433848.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 192852912.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 95348960.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 177946784.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 141158864.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 146747008.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 152859456.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 146049664.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 106470864.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 104298472.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 87482320.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 130227904.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 124791456.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 154686160.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 92075752.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 116372160.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 289350784.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 149278416.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 175876000.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 123838544.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 154898400.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 135267008.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 289360448.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 103167680.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 130073824.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 80791312.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 138407648.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 114464504.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 232414112.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 136105344.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 178810432.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 171158080.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 131442920.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 180181552.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 158336416.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 106277448.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 112389208.0000\n",
            "============================================================\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 148374000.0000\n",
            "============================================================\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 210583120.0000\n",
            "============================================================\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 108107696.0000\n",
            "============================================================\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 157532928.0000\n",
            "============================================================\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 134825776.0000\n",
            "============================================================\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 170131296.0000\n",
            "============================================================\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 104597680.0000\n",
            "============================================================\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 178595008.0000\n",
            "============================================================\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 138746080.0000\n",
            "============================================================\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 153391696.0000\n",
            "============================================================\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 132226000.0000\n",
            "============================================================\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 101369464.0000\n",
            "============================================================\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 130743232.0000\n",
            "============================================================\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 111459808.0000\n",
            "============================================================\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 97319280.0000\n",
            "============================================================\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 124050016.0000\n",
            "============================================================\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 227825664.0000\n",
            "============================================================\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 165588096.0000\n",
            "============================================================\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 97538816.0000\n",
            "============================================================\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 224763344.0000\n",
            "============================================================\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 165815968.0000\n",
            "============================================================\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 185710480.0000\n",
            "============================================================\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 121716584.0000\n",
            "============================================================\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 122362200.0000\n",
            "============================================================\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 216013664.0000\n",
            "============================================================\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 178905616.0000\n",
            "============================================================\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 179790512.0000\n",
            "============================================================\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 170904352.0000\n",
            "============================================================\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 66394268.0000\n",
            "============================================================\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 114703488.0000\n",
            "============================================================\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 146002048.0000\n",
            "============================================================\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 109886840.0000\n",
            "============================================================\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 112032144.0000\n",
            "============================================================\n",
            "Current Batch :0\n",
            "Batch[1/1000], Loss: 181690464.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 181690464.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :1\n",
            "Batch[2/1000], Loss: 170236080.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 170236080.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :2\n",
            "Batch[3/1000], Loss: 143225888.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 143225888.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :3\n",
            "Batch[4/1000], Loss: 86657640.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 86657640.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :4\n",
            "Batch[5/1000], Loss: 160922992.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 160922992.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :5\n",
            "Batch[6/1000], Loss: 153150288.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 153150288.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :6\n",
            "Batch[7/1000], Loss: 100305336.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 100305336.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :7\n",
            "Batch[8/1000], Loss: 223711584.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 223711584.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :8\n",
            "Batch[9/1000], Loss: 111484312.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 111484312.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :9\n",
            "Batch[10/1000], Loss: 174116688.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 174116688.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :10\n",
            "Batch[11/1000], Loss: 163517328.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 163517328.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :11\n",
            "Batch[12/1000], Loss: 160951392.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 160951392.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :12\n",
            "Batch[13/1000], Loss: 99638624.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 99638624.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :13\n",
            "Batch[14/1000], Loss: 169909184.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 169909184.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :14\n",
            "Batch[15/1000], Loss: 166212128.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 166212128.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :15\n",
            "Batch[16/1000], Loss: 178684656.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 178684656.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :16\n",
            "Batch[17/1000], Loss: 194401936.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 194401936.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :17\n",
            "Batch[18/1000], Loss: 86413664.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 86413664.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :18\n",
            "Batch[19/1000], Loss: 133776056.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 133776056.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :19\n",
            "Batch[20/1000], Loss: 87638952.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 87638952.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :20\n",
            "Batch[21/1000], Loss: 118927976.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 118927976.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :21\n",
            "Batch[22/1000], Loss: 152212736.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 152212736.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :22\n",
            "Batch[23/1000], Loss: 181424528.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 181424528.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :23\n",
            "Batch[24/1000], Loss: 225143232.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 225143232.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :24\n",
            "Batch[25/1000], Loss: 180097616.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 180097616.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :25\n",
            "Batch[26/1000], Loss: 112739216.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 112739216.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :26\n",
            "Batch[27/1000], Loss: 115375128.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 115375128.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :27\n",
            "Batch[28/1000], Loss: 72459736.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 72459736.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :28\n",
            "Batch[29/1000], Loss: 96944912.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 96944912.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :29\n",
            "Batch[30/1000], Loss: 103325696.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 103325696.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :30\n",
            "Batch[31/1000], Loss: 179486560.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 179486560.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :31\n",
            "Batch[32/1000], Loss: 193125040.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 193125040.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :32\n",
            "Batch[33/1000], Loss: 91800528.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 91800528.0000\n",
            "************************************************************************************************************************\n",
            "Current Batch :33\n",
            "Batch[34/1000], Loss: 157283488.0000\n",
            "============================================================\n",
            "************************************************************************************************************************\n",
            "Epoch [1000/1000], Loss: 157283488.0000\n",
            "************************************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lfbf77E04tB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}